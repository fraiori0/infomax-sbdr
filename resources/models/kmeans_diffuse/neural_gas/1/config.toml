[model]
type = "NeuralGas"
seed = 42
# activation = "leaky_relu"
# out_activation = "sigmoid"
[model.kwargs]
n_units = 256
in_features = 784
epsilon_0 = 0.3
epsilon_f = 0.01
lambda_f = 0.1
topk = 15

[dataset.transform.normalization]
mean = [0.2860]
std = [0.3530]
[dataset.transform.resized_crop]
size = 28
scale = [0.9, 1.0]
ratio = [0.99, 1.01]
[dataset.transform.flip]
p = 0.5
[dataset.transform.grayscale]
p = 0.1
[dataset.transform.color_jitter]
brightness = 0.15
contrast = 0.15
saturation = 0.15
hue = 0.15

[training]
epochs = 5
batch_size = 8

[training.checkpoint]
save = true
save_interval = 1 # epochs
max_to_keep = 10

[training.dataloader]
shuffle = true
# drop the last batch to avoid recompiling jitted functions because of changing input dims
# see here https://flax-linen.readthedocs.io/en/latest/guides/data_preprocessing/full_eval.html
drop_last = true


[validation]
split = 0.16
eval_interval = 12
[validation.dataloader]
batch_size = 256
[validation.sim_fn]
type = "log_and"
quantile = 0.9
[validation.sim_fn.kwargs]
eps = 1.0e-2
